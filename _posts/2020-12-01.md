---
title: 'Thoughts on Bias Detection'
date: 2020-12-01
permalink: /posts/2020-12-01
tags:
  - research
  - data science
  - media
---

Lately, I've been contemplating about starting a project on disinformation detection using data sources from Twitter and major news outlets. As with any research endeavor, the initial steps towards problem definition are most difficult. Here, I want to briefly talk about the thoughts behind this project and the challenges I've presented myself. At the present moment, my thoughts are still quite unstructured, but overtime, I'm confident the overarching scope will become clearer to me. 

Fake news detection is a hot area of data science in the private and public sectors. Almost every major news outlet or government-funded media research institution has invested in it. The idea at the very top level is not too sophisticated; all you need to do is using machine learning algorithms to build a classification or regression model that categorizes a specific piece of textual content from Twitter or Facebook as "real" or "fabricated". One issue of this approach, however, is labeling - how do we objectively classify news articles in the first place? It is fairly common to bypass this issue by using known "fake news" datasets, where tens of thousands of Tweets or Buzzfeed news in the rabbithole are pre-labeled. However, with my usual skeptical self, using an established dataset without questioning its reliability is quite against the purpose of the project I've conceived - my goal here is precisely to investigate text without assumptions. However, this does not mean I will be building my own sample entirely from scratch - it is not my place to reject all open source data. I simply want to be very mindful of the hypotheses that the project relies on.

As we all may have experienced, classifying fake news is far from a black-and-white task. Oftentimes facts and fabricated claims are separated by a very fine line. It's quite hard to find a piece of Tweet or news that has absolutely no truth in it - even radical opinions are comprised of some elements of truth (and this, of course, is what makes this area of data science so interesting). In addition, characteristics of what we colloquially define as "fake news" - news with fabricated information built intentionally to deceive - could be so varied that it's quite difficult to establish uniform features for hard classification. Furthermore, so much focus is on what's being said rather than what's not. Major news outlets have a tendency to omit evidence that counter their narratives. However, since we are relying on textual data for these sorts of analyses, 

1. 
