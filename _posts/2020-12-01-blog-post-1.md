---
title: 'Thoughts on Bias Detection'
date: 2020-12-01
permalink: /posts/2020/12/thoughts-on-bias-detection/
tags:
  - research
  - data science
  - media
---

Lately, I've been contemplating about starting a project on fake news detection using data sources from Twitter and major news outlets. As with any research endeavor, the initial steps towards problem definition are most difficult. Here, I want to briefly talk about the thoughts behind this project and the challenges I envisioned. As I'm writing this post, my thoughts are still quite unstructured, but over time, I'm confident the project scope will become clear to me. 

Fake news detection is a hot area of data science; almost every major news outlet or government-funded media research institution invests in it. In essence, a machine learning algorithm is built to classify textual content as "real" or "fabricated". One issue of this approach, however, is labeling &ndash; what reference frame should we rely upon to categorize these news articles? It is fairly common to bypass the task of labeling by using prelabeled datasets (for instance, FakeNewsNet). However, using an established dataset without questioning how it came about is quite against the purpose of the project. Note that it does not mean I've decided to build my own dataset from scratch &ndash; I simply want to be mindful of the data collection processes that the project relies on.

Before I discuss my vision for this project, I want to outline some of the challenges of traditional fake news detection.

First, classifying fake news is not a black-and-white task. Facts and fabricated claims are separated by a very fine line. It's quite hard to find a piece of Tweet or news that has absolutely no truth in it &ndash; conversely, radical content also contains a certain degree of truth. 

In addition, the linguistic structures of what we colloquially define as "fake news" &ndash; news created intentionally to deceive &ndash; are so varied that it's quite difficult to establish uniform features for hard classification. 

Furthermore, as we build natural language processing pipelines, our focus is on what's being written rather than what's not. Studies have shown that journalists and content curators tend to omit evidence that counters their narratives. Solely relying on text-based data would lead us to overlook what's held back.

Finally, there's an inherent difference between disinformation, which is intentionally deceptive, and misinformation, which encompasses all types of misleading or inaccurate information. Machine learning algorithms may be able to detect specific rhetorical or semantic structures to differentiate fact from fiction, but the task is more complicated when the authors of falsified news believe in their own content. To overcome this challenge, we will need to deal with the presentation of "intention" as well as that of "bias", which is very hard to quantify.

This last point of consideration, on the other hand, opened up a new path for me to explore. Rather than developing hard classification rules for fake news detection, I find bias detection to be a much more interesting topic. For one, bias is everywhere, and therefore my potential data sources will be abundant. Even the most reputable news outlets curate content that could unintentionally lead to misunderstanding and polarization. Futhermore, I believe it's impossible to develop a reference frame that communicates absolute truth, and I'm not entirely comfortable with the idea of "imposing" any sort of hard rules on something fundamentally grounded in subjectivity. 

One idea for my project is to quantify our perception of media bias by analyzing the semantic and rhetorical structures of news articles from different web sources. Ultimately, I hope this project could contribute to some of the philosophical discussions our society as a whole has been struggling with, such as the danger of political polarization, the controversy of free speech, and the economic incentivization of speech as spectacle.


